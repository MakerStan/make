<!DOCTYPE html>
<html lang=en>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name=viewport content="width=device-width, initial-scale=1.0">
<meta name=description content="This post describe how you can check for dead links on your website. I used the Linux command wget for this.">
<meta name=author content="StanGeorge">
<title>Find dead links on your website | Make</title>
<link rel="shortcut icon" href="ico/favicon.ico" />
<meta name="generator" content="DocPad v6.69.1" />

<link rel=stylesheet href="http://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css">
<link href="http://d27jzba8aj5ptt.cloudfront.net/jumbotron-narrow.min.css" rel=stylesheet>
<!--[if lt IE 9]>
      <script src="../../assets/js/html5shiv.js"></script>
      <script src="../../assets/js/respond.min.js"></script>
    <![endif]-->
<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-43034225-4','stanleygeorge.com');ga('send','pageview');</script>
</head>
<body>
  <div class=container>
    <div class=header>
      <h2 class=text-muted>
        <a href="index.html">Home / </a>Find dead links on your website
      </h2>
    </div>
    <div class=jumbotron><p class=lead style="text-align:justify;">
      This post describe how you can check for dead links on your website. I used the Linux command wget for this.
    </div>
    <p style="text-align:justify;">
      <p><strong>WORK IN PROGRESS</strong><br />
I created my website using docpad. I have it locally running as described in <a href="static-website-docpad.html.md">this post</a>. I want to check if I have any dead links on this site. The <code>wget</code> command in Linux helps me do this. </p>
<ol>
<li>The &#39;spider&#39; option is to enable crawling recursively (--recursive option). </li>
<li>The --base option specifies a base url for the link on my website that are just file names such as <code>&lt;a href=&quot;index.html&quot;&gt;Home&lt;/a&gt;</code> instead of fully qualified URLs.</li>
</ol>
<pre>
wget --spider --recursive --level=1 --force-html --input-file="out/index.html" --base="http://localhost:9778/" -Dlocalhost --delete-after --no-cache
</pre>

<p><strong>TODO:</strong> Right now this command gives me a lot of output. I do find 404 messages and the broken links, but I need to scroll through the output. One solution is to provice the <code>-o</code> option to have the output routed to a file and then run a <code>grep</code> command to search for 404 errors.</p>
<p>A related task is to find all references to a file in other files. I can do this to get only the files names of other files have a link to &#39;index.html&#39;</p>
<pre>grep -H "index.html" out/* | cut -d: -f1</pre>
      
    </p>
    <div class=footer>
      Created by <a href="https://github.com/StanGeorge">StanGeorge</a> on April 6, 2014. Last updated on April 6, 2014.<br />
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by/4.0/80x15.png" /></a> This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
    </div>
  </div>
</body>
</html>
